{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\">Syllabus Ciencia de datos</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Profesor</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Alvaro Montenegro. email: ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qwzm74tvByHP"
   },
   "source": [
    "Este documento presenta el contenido del curso de ciencia de datos que se dicta en el Departamento de Estadística de la Universidad Nacional de Colombia, Sede Bogotá."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "## <span style=\"color:#4361EE\">El término ciencia de datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "La Ciencia de Datos tiene su origen en el año 1962, cuando el estadístico estadounidense John W. Tukey, conocido por el desarrollo de complejos algoritmos y el famoso diagrama de caja y bigotes (Box Plot), escribe y se cuestiona el futuro de la estadística como ciencia empírica. Escribiría así en “El futuro del análisis de datos” (1962):\n",
    "\n",
    "“Durante mucho tiempo pensé que era un estadístico interesado en inferencias de lo particular a lo general. Pero a medida que observé la evolución de las estadísticas matemáticas, tuve motivos para preguntarme y dudar […] Llegué a sentir que mi interés central está en el análisis de datos… El análisis de datos, y las partes de las estadísticas que se adhieren a él, deben […] asumir las características de la ciencia en lugar de las matemáticas […] el análisis de datos es intrínsecamente una ciencia empírica”.\n",
    "\n",
    "En estas declaraciones se habla por primera vez de la evolución de la estadística matemática como Ciencia de Datos. Sin embargo, no sería hasta más adelante en 1974 cuando Peter Naur, científico danés conocido por sus trabajos en las ciencias computacionales y ganador del premio Turing en el año 2005, acuñara el término que actualmente conocemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Montenegro y Daniel Montenegro, 2022, [Fundamentos de programación, Biblioteca Alejandría](https://github.com/AprendizajeProfundo/Libro_Fundamentos_Programacion).\n",
    "1. Alvaro Montenegro y Daniel Montenegro, 2022, [Big data, Biblioteca Alejandría](https://github.com/AprendizajeProfundo/BigData).\n",
    "1. Alvaro Montenegro y Daniel Montenegro, 2022, [Optimización, Gradiente descendiente estocástico, Biblioteca Alejandría](https://github.com/AprendizajeProfundo/Libro-Fundamentos/blob/main/Fundamentacion_Matematica/Cuadernos/am-sdg.ipynb)\n",
    "1. Alvaro Montenegro y Daniel Montenegro, 2022, [Introducción a tensores, Biblioteca Alejandría](https://github.com/AprendizajeProfundo/Diplomado-Avanzado/blob/main/Matem%C3%A1ticas%20y%20Estad%C3%ADstica%20de%20la%20IA/Cuadernos/Intro_Tensores_II.ipynb)\n",
    "1. Alvaro Montenegro y Daniel Montenegro, 2022, [Conceptos básicos de Teoría de la Información, Biblioteca Alejandría](https://github.com/AprendizajeProfundo/Diplomado-Avanzado/blob/main/Matem%C3%A1ticas%20y%20Estad%C3%ADstica%20de%20la%20IA/Cuadernos/ti_Teoria_Informacion.ipynb)\n",
    "1.  Christofer. M. Bishop, *Pattern Recognition and machine Learning*, first edition,Springer, 2006\n",
    "1. Solomon Kullback, *Information Theory and Statistics*, Dover Publications, Inc, 1968\n",
    "1. Robert B.  Ash, *Information Theory*, Dover Publications, Inc, 1990.\n",
    "1. James V Stone, [Information Theory: A Tutorial Introduction](https://arxiv.org/pdf/1802.05968.pdf)\n",
    "1. [Scikit-learn](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Evaluación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tareas 20\\%\n",
    "* Proyecto de curso 70\\%\n",
    "* Presentación final del proyecto 10\\%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "## <span style=\"color:#4361EE\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Programación Python</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* Introducción\n",
    "* Variables y tipos de datos\n",
    "* Operadores aritméticos y lógicos\n",
    "* Estructuras de control\n",
    "* Funciones\n",
    "* Iterables\n",
    "* Tuplas, listas, diccionarios, conjuntos\n",
    "* Numpy\n",
    "* Pandas\n",
    "* Matplotlib\n",
    "* Scipy\n",
    "* Principios de procesamiento paralelo y big data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Matemáticas y Teoría de la Información</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* Optimización moderna. Gradiente descendiente estocástico\n",
    "* Tensores\n",
    "* Teoría de la información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Reducción de dimensión</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* Concepto de dimensión y q-dimensión\n",
    "* Reducción lineal de dimensión: Análisis de Componentes principales (PCA)\n",
    "* Análisis de componentes independientes (ICA)\n",
    "* Métodos basados en variedades: Isomap \n",
    "* Extracción de características (features)\n",
    "* Factorizacion matricial no negativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Preprocesamiento</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* Estandarización de características\n",
    "* Escalamiento con datos dispersos y outliers\n",
    "* Transformaciones no lineales. Transformación a escala $[0,1 ]$\n",
    "* Codificación de variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Clasificación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* Maquinas de soporte vectorial (SVM)\n",
    "* Vecinos más cercanos\n",
    "* Métodos ensamblados: bosques aleatorios (random forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Regresión</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* Regresión lineal.\n",
    "* Regresión logística.\n",
    "* Modelos generales de regresión: MLG, GAMLSS.\n",
    "* Regresión robusta.\n",
    "* Regresión por vecinos más cercanos.\n",
    "* Modelos ensamblados: random forests, gradient boosting.\n",
    "* Modelos neuronales: perceptrón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Agrupamiento (Clustering)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* kmeans\n",
    "* dbscan\n",
    "* Desplazamiento de la media\n",
    "* Agrupamiento espectral\n",
    "* Métodos ensamblados: gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Selección de modelos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "* Búsqueda po grilla\n",
    "* Validación cruzada\n",
    "* Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzyZQ2syLu9O"
   },
   "source": [
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
